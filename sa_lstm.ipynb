{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374a5f79-30ca-4b7c-9d89-1c04d22258d2",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0eceb29-d217-4886-bf41-47a25d77182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Mubuky\\.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06c156",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import warnings\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aee5b72-12ce-433e-ae30-b0fe6de13a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea89b9a-3b2b-4a99-b386-4581e327f98d",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8d10ef-7eae-4121-9f71-5737941aa100",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "\t'seed': 5201314,\n",
    "\t'batch_size': 64,\n",
    "\t'learning_rate': 5e-4,\n",
    "\t'num_workers': 8,\n",
    "\t'save_path': './models/',\n",
    "#\t'output_path': './pred.csv',\n",
    "\t'n_epochs': 10,\n",
    "    'clip_norm': 0.75,\n",
    "    'padding_length': 108,\n",
    "    'num_classes': 4  # -2, -1, 0, 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce649823-963e-4c75-afb8-8ead00e8fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmubuky\u001b[0m (\u001b[33macsdf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Jupyter Notebook\\sa\\wandb\\run-20240227_175001-v4qra3db</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/acsdf/SA/runs/v4qra3db' target=\"_blank\">LSTM</a></strong> to <a href='https://wandb.ai/acsdf/SA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/acsdf/SA' target=\"_blank\">https://wandb.ai/acsdf/SA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/acsdf/SA/runs/v4qra3db' target=\"_blank\">https://wandb.ai/acsdf/SA/runs/v4qra3db</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/acsdf/SA/runs/v4qra3db?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x217bfa95a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = \"SA\",\n",
    "    name = \"LSTM\",\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff5478-1582-4f12-a070-ccd6fbaee273",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230cac44-d1fb-4a41-a0a6-8b7d86c21172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "df_train = pd.read_csv(data_path + 'train.csv')\n",
    "df_valid = pd.read_csv(data_path + 'valid.csv')\n",
    "df_testa = pd.read_csv(data_path + 'testa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243071b2-7e4b-4d22-b727-6865807f9851",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aeafb44-7d07-4513-8e9f-178f70404a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                            -2                                        -2   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                     -2                 -2                         1   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  ...  \\\n",
       "0                           -2                     -2           -2  ...   \n",
       "\n",
       "   environment_decoration  environment_noise  environment_space  \\\n",
       "0                      -2                 -2                 -2   \n",
       "\n",
       "   environment_cleaness  dish_portion  dish_taste  dish_look  \\\n",
       "0                    -2            -2          -2          1   \n",
       "\n",
       "   dish_recommendation  others_overall_experience  \\\n",
       "0                   -2                          1   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                               -2  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2a6e4c-7439-4995-83b9-680243a59bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>price_cost_effective</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105000.00000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105000.00000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52499.50000</td>\n",
       "      <td>-1.360267</td>\n",
       "      <td>-1.407095</td>\n",
       "      <td>-1.402276</td>\n",
       "      <td>-1.749895</td>\n",
       "      <td>-0.496495</td>\n",
       "      <td>-1.846952</td>\n",
       "      <td>-1.661457</td>\n",
       "      <td>-0.975800</td>\n",
       "      <td>-1.379238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.67160</td>\n",
       "      <td>-1.203162</td>\n",
       "      <td>-1.065410</td>\n",
       "      <td>-1.033552</td>\n",
       "      <td>-0.907552</td>\n",
       "      <td>0.389181</td>\n",
       "      <td>-1.275771</td>\n",
       "      <td>-1.484181</td>\n",
       "      <td>0.537771</td>\n",
       "      <td>-0.981248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30311.03347</td>\n",
       "      <td>1.210342</td>\n",
       "      <td>1.185697</td>\n",
       "      <td>1.145902</td>\n",
       "      <td>0.739263</td>\n",
       "      <td>1.358622</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.866716</td>\n",
       "      <td>1.151532</td>\n",
       "      <td>1.166656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41387</td>\n",
       "      <td>1.266776</td>\n",
       "      <td>1.282662</td>\n",
       "      <td>1.337833</td>\n",
       "      <td>1.308446</td>\n",
       "      <td>0.781373</td>\n",
       "      <td>1.224178</td>\n",
       "      <td>1.095536</td>\n",
       "      <td>0.740198</td>\n",
       "      <td>1.372485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26249.75000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52499.50000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78749.25000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104999.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  location_traffic_convenience  \\\n",
       "count  105000.00000                 105000.000000   \n",
       "mean    52499.50000                     -1.360267   \n",
       "std     30311.03347                      1.210342   \n",
       "min         0.00000                     -2.000000   \n",
       "25%     26249.75000                     -2.000000   \n",
       "50%     52499.50000                     -2.000000   \n",
       "75%     78749.25000                     -2.000000   \n",
       "max    104999.00000                      1.000000   \n",
       "\n",
       "       location_distance_from_business_district  location_easy_to_find  \\\n",
       "count                             105000.000000          105000.000000   \n",
       "mean                                  -1.407095              -1.402276   \n",
       "std                                    1.185697               1.145902   \n",
       "min                                   -2.000000              -2.000000   \n",
       "25%                                   -2.000000              -2.000000   \n",
       "50%                                   -2.000000              -2.000000   \n",
       "75%                                   -2.000000              -2.000000   \n",
       "max                                    1.000000               1.000000   \n",
       "\n",
       "       service_wait_time  service_waiters_attitude  \\\n",
       "count      105000.000000             105000.000000   \n",
       "mean           -1.749895                 -0.496495   \n",
       "std             0.739263                  1.358622   \n",
       "min            -2.000000                 -2.000000   \n",
       "25%            -2.000000                 -2.000000   \n",
       "50%            -2.000000                  0.000000   \n",
       "75%            -2.000000                  1.000000   \n",
       "max             1.000000                  1.000000   \n",
       "\n",
       "       service_parking_convenience  service_serving_speed    price_level  \\\n",
       "count                105000.000000          105000.000000  105000.000000   \n",
       "mean                     -1.846952              -1.661457      -0.975800   \n",
       "std                       0.618700               0.866716       1.151532   \n",
       "min                      -2.000000              -2.000000      -2.000000   \n",
       "25%                      -2.000000              -2.000000      -2.000000   \n",
       "50%                      -2.000000              -2.000000      -2.000000   \n",
       "75%                      -2.000000              -2.000000       0.000000   \n",
       "max                       1.000000               1.000000       1.000000   \n",
       "\n",
       "       price_cost_effective  ...  environment_decoration  environment_noise  \\\n",
       "count         105000.000000  ...            105000.00000      105000.000000   \n",
       "mean              -1.379238  ...                -0.67160          -1.203162   \n",
       "std                1.166656  ...                 1.41387           1.266776   \n",
       "min               -2.000000  ...                -2.00000          -2.000000   \n",
       "25%               -2.000000  ...                -2.00000          -2.000000   \n",
       "50%               -2.000000  ...                -2.00000          -2.000000   \n",
       "75%               -2.000000  ...                 1.00000           0.000000   \n",
       "max                1.000000  ...                 1.00000           1.000000   \n",
       "\n",
       "       environment_space  environment_cleaness   dish_portion     dish_taste  \\\n",
       "count      105000.000000         105000.000000  105000.000000  105000.000000   \n",
       "mean           -1.065410             -1.033552      -0.907552       0.389181   \n",
       "std             1.282662              1.337833       1.308446       0.781373   \n",
       "min            -2.000000             -2.000000      -2.000000      -2.000000   \n",
       "25%            -2.000000             -2.000000      -2.000000       0.000000   \n",
       "50%            -2.000000             -2.000000      -2.000000       1.000000   \n",
       "75%             0.000000              1.000000       1.000000       1.000000   \n",
       "max             1.000000              1.000000       1.000000       1.000000   \n",
       "\n",
       "           dish_look  dish_recommendation  others_overall_experience  \\\n",
       "count  105000.000000        105000.000000              105000.000000   \n",
       "mean       -1.275771            -1.484181                   0.537771   \n",
       "std         1.224178             1.095536                   0.740198   \n",
       "min        -2.000000            -2.000000                  -2.000000   \n",
       "25%        -2.000000            -2.000000                   0.000000   \n",
       "50%        -2.000000            -2.000000                   1.000000   \n",
       "75%        -1.000000            -2.000000                   1.000000   \n",
       "max         1.000000             1.000000                   1.000000   \n",
       "\n",
       "       others_willing_to_consume_again  \n",
       "count                    105000.000000  \n",
       "mean                         -0.981248  \n",
       "std                           1.372485  \n",
       "min                          -2.000000  \n",
       "25%                          -2.000000  \n",
       "50%                          -2.000000  \n",
       "75%                           1.000000  \n",
       "max                           1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb457b5c-c6b6-42ab-8635-42f654dcc985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "1\n",
      "content\n",
      "0\n",
      "location_traffic_convenience\n",
      "81382\n",
      "location_distance_from_business_district\n",
      "83680\n",
      "location_easy_to_find\n",
      "80605\n",
      "service_wait_time\n",
      "92763\n",
      "service_waiters_attitude\n",
      "42410\n",
      "service_parking_convenience\n",
      "98276\n",
      "service_serving_speed\n",
      "88700\n",
      "price_level\n",
      "52820\n",
      "price_cost_effective\n",
      "80242\n",
      "price_discount\n",
      "64243\n",
      "environment_decoration\n",
      "53916\n",
      "environment_noise\n",
      "73445\n",
      "environment_space\n",
      "65398\n",
      "environment_cleaness\n",
      "66598\n",
      "dish_portion\n",
      "56917\n",
      "dish_taste\n",
      "55367\n",
      "dish_look\n",
      "75975\n",
      "dish_recommendation\n",
      "84767\n",
      "others_overall_experience\n",
      "70070\n",
      "others_willing_to_consume_again\n",
      "65600\n"
     ]
    }
   ],
   "source": [
    "for column in df_train:\n",
    "    print(column)\n",
    "    prt = max(\n",
    "        sum(df_train[column] == -2), \n",
    "        sum(df_train[column] == -1), \n",
    "        sum(df_train[column] == 0), \n",
    "        sum(df_train[column] == 1)\n",
    "    )\n",
    "    print(prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633d04cf-1cd0-46c4-9d40-03c7b2b9391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_waiters_attitude\n",
       "-2    42410\n",
       " 1    41372\n",
       " 0    12534\n",
       "-1     8684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['service_waiters_attitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc4492c-8cf3-44b1-b3a3-aea7ecf3e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[ : , ['content', 'service_waiters_attitude']]\n",
    "df_valid = df_valid.loc[ : , ['content', 'service_waiters_attitude']]\n",
    "df_testa = df_testa.loc[ : , ['content', 'service_waiters_attitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67100c23-c11f-4269-bd27-bd3e87cc1781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  service_waiters_attitude\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...                         1\n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...                        -2\n",
       "2  \"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...                         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb5309-8745-4e63-a319-d8e5dd36d945",
   "metadata": {},
   "source": [
    "## Pretreatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7989a-d9dd-48e6-b8c5-cb8ebf3b631a",
   "metadata": {},
   "source": [
    "### 繁体转简体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c1d3f4-c5d3-41d3-8de4-1a3afdd2928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencc import OpenCC\n",
    "\n",
    "cc = OpenCC('t2s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de70b66-c392-4143-8893-4659bc4bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(lambda x:cc.convert(x))\n",
    "df_valid['content'] = df_valid['content'].apply(lambda x:cc.convert(x))\n",
    "df_testa['content'] = df_testa['content'].apply(lambda x:cc.convert(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0e8c0-31ae-44d4-9a80-8cac4aaee06c",
   "metadata": {},
   "source": [
    "### 正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c154afa4-0d6b-418b-8a21-8e82646b5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_sentence(content):\n",
    "    decimal_regex = re.compile(r\"[^a-zA-Z]\\d+\")\n",
    "\n",
    "    content = content.replace(\"\\r\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    content = decimal_regex.sub(r\"\", content)\n",
    "\n",
    "    #return \"\".join(re.findall('[\\u4e00-\\u9fa5]+', content, re.S))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "833ea410-effd-4527-bbd2-78f3f3c766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(lambda x:regular_sentence(x))\n",
    "df_valid['content'] = df_valid['content'].apply(lambda x:regular_sentence(x))\n",
    "df_testa['content'] = df_testa['content'].apply(lambda x:regular_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f081a70-1700-4484-9feb-5d9f070e5602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  service_waiters_attitude\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...                         1\n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...                        -2\n",
       "2  人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...                         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d5aa5-6b78-4128-9a4b-ce344e19ec11",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5cc20a-4730-4372-a75b-a8c5ff0d2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "#filePath = 'D:\\\\Jupyter Notebook\\\\sa\\\\jieba_dict\\\\'\n",
    "#filelist = os.listdir(filePath)\n",
    "#for i in range(len(filelist)):\n",
    "#    jieba.load_userdict(filePath + filelist[i])\n",
    "#jieba.load_userdict(\"add_words_ch.txt\")\n",
    "\n",
    "def separate(content):\n",
    "    return \" \".join(jieba.cut(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08eb30d8-fc0e-4ab4-8d9f-d76f7a912694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Mubuky\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.492 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "df_train['sep_content'] = df_train['content'].apply(lambda x:separate(x))\n",
    "df_valid['sep_content'] = df_valid['content'].apply(lambda x:separate(x))\n",
    "df_testa['sep_content'] = df_testa['content'].apply(lambda x:separate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9eb152d-b294-45a1-b3eb-6f46b30343ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>sep_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "      <td>\" 吼吼 吼 ， 萌死 人 的 棒棒糖 ， 中 了 大众 点评 的 霸王餐 ， 太 可爱 了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>\" 第三次 参加 大众 点评 网 霸王餐 的 活动 。 这家 店 给 人 整体 感觉 一般 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...</td>\n",
       "      <td>0</td>\n",
       "      <td>人 同行   点个 小吃   榴莲 酥   榴莲 味道 不足   松软   奶味 浓   虾...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2  人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...   \n",
       "\n",
       "   service_waiters_attitude                                        sep_content  \n",
       "0                         1  \" 吼吼 吼 ， 萌死 人 的 棒棒糖 ， 中 了 大众 点评 的 霸王餐 ， 太 可爱 了...  \n",
       "1                        -2  \" 第三次 参加 大众 点评 网 霸王餐 的 活动 。 这家 店 给 人 整体 感觉 一般 ...  \n",
       "2                         0  人 同行   点个 小吃   榴莲 酥   榴莲 味道 不足   松软   奶味 浓   虾...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b0d94-94fb-4c14-b7bf-e311fdb7b3ea",
   "metadata": {},
   "source": [
    "### 删去单字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a16a0aae-7975-45e3-82d4-289676322806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeunique(sentence):\n",
    "    segs = [word for word in sentence.split() if len(word) > 1]\n",
    "    return \" \".join(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50e30840-ad0a-46aa-8f75-bb2f64297db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sep_content'] = df_train['sep_content'].apply(lambda x:excludeunique(x))\n",
    "df_valid['sep_content'] = df_valid['sep_content'].apply(lambda x:excludeunique(x))\n",
    "df_testa['sep_content'] = df_testa['sep_content'].apply(lambda x:excludeunique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d08d703-b6fd-4ac4-aeb5-85328ee764b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>sep_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "      <td>吼吼 萌死 棒棒糖 大众 点评 霸王餐 可爱 一直 好奇 这个 棒棒糖 怎么 东西 大众 点...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>第三次 参加 大众 点评 霸王餐 活动 这家 整体 感觉 一般 首先 环境 只能 中等 其次...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...</td>\n",
       "      <td>0</td>\n",
       "      <td>同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 但...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2  人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...   \n",
       "\n",
       "   service_waiters_attitude                                        sep_content  \n",
       "0                         1  吼吼 萌死 棒棒糖 大众 点评 霸王餐 可爱 一直 好奇 这个 棒棒糖 怎么 东西 大众 点...  \n",
       "1                        -2  第三次 参加 大众 点评 霸王餐 活动 这家 整体 感觉 一般 首先 环境 只能 中等 其次...  \n",
       "2                         0  同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 但...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d927416-4a8e-4bb7-85f4-3a0c594ada49",
   "metadata": {},
   "source": [
    "### 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40fe0769-ab22-4d29-866c-6f8026e394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludestops(sentence, stop_words):\n",
    "    segs = [word for word in sentence.split() if word not in stop_words]\n",
    "    return \" \".join(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9957fd5c-6763-45fb-a647-305eae0d0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set()\n",
    "with open('stopwords.txt', encoding='utf-8') as f:\n",
    "    con = f.readlines()\n",
    "    for i in con:\n",
    "        i = i.replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\")\n",
    "        stop_words.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a6f94ad-6421-4c1e-a556-c8bec620f742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "892ccf50-e160-4657-ba8f-86d8881ff132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sep_content'] = df_train['sep_content'].apply(lambda x:excludestops(x, stop_words))\n",
    "df_valid['sep_content'] = df_valid['sep_content'].apply(lambda x:excludestops(x, stop_words))\n",
    "df_testa['sep_content'] = df_testa['sep_content'].apply(lambda x:excludestops(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb3ff5a-13c6-4ee9-85ee-e6b025741f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>sep_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "      <td>萌死 棒棒糖 可爱 好奇 棒棒糖 东西 土老冒 见识 机会 介绍 棒棒糖 德国 不会 很甜 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>参加 活动 这家 整体 感觉 环境 只能 中等 提供 菜品 不是 很多 当然 商家 避免 参...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...</td>\n",
       "      <td>0</td>\n",
       "      <td>同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 奶...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2  人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...   \n",
       "\n",
       "   service_waiters_attitude                                        sep_content  \n",
       "0                         1  萌死 棒棒糖 可爱 好奇 棒棒糖 东西 土老冒 见识 机会 介绍 棒棒糖 德国 不会 很甜 ...  \n",
       "1                        -2  参加 活动 这家 整体 感觉 环境 只能 中等 提供 菜品 不是 很多 当然 商家 避免 参...  \n",
       "2                         0  同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 奶...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd963b-cc18-4636-89de-196bc54bbaee",
   "metadata": {},
   "source": [
    "### 删去词频较低的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9cca2d4-19b7-4e22-a983-2478756fdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = list(df_train['sep_content'])\n",
    "sentences_valid = list(df_valid['sep_content'])\n",
    "sentences_testa = list(df_testa['sep_content'])\n",
    "sentences = sentences_train + sentences_valid + sentences_testa\n",
    "word_list = \" \".join(sentences).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c22d10ed-280f-45d5-a4a4-0259bc528151",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = collections.Counter(word_list)\n",
    "\n",
    "expand_stop_words = set()\n",
    "for key in counts:\n",
    "    if counts[key] <= 2:\n",
    "        expand_stop_words.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eda16a5-fa35-44e7-8c77-84152d1b4dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155313"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expand_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38092e14-3870-451f-a4a8-9739bd5fc41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('味道', 159960), ('不错', 156026), ('感觉', 118353), ('好吃', 107818), ('没有', 96754), ('喜欢', 70502), ('服务员', 69611), ('环境', 61992), ('这家', 60543), ('里面', 59997), ('服务', 58274), ('不是', 53692), ('特别', 52421), ('觉得', 50659), ('口味', 47891), ('推荐', 46540), ('很多', 46263), ('菜品', 40383), ('新鲜', 37286), ('价格', 35879), ('口感', 35609), ('牛肉', 35431), ('朋友', 34881), ('位置', 31320), ('最后', 30369), ('团购', 29397), ('他家', 29045), ('知道', 28272), ('看到', 26308), ('起来', 26276), ('干净', 25690), ('装修', 25630), ('餐厅', 25300), ('老板', 25295), ('个人', 24601), ('不会', 24074), ('店里', 23698), ('这次', 23295), ('总体', 22816), ('海鲜', 22753), ('特色', 22638), ('地方', 22329), ('其实', 21561), ('东西', 21429), ('可能', 21333), ('来说', 20396), ('芝士', 20232), ('火锅', 19457), ('套餐', 19311), ('大家', 19147), ('方便', 19062), ('之前', 19028), ('很大', 18638), ('便宜', 18545), ('选择', 18234), ('入味', 18131), ('现在', 18109), ('附近', 17984), ('出来', 17526), ('热情', 17436), ('活动', 17377), ('以后', 17272), ('豆腐', 17017), ('超级', 16943), ('店家', 16887), ('适合', 16782), ('饮料', 16552), ('交通', 16507), ('吃饭', 16202), ('上菜', 16002), ('过来', 15605), ('旁边', 15597), ('蛋糕', 15472), ('发现', 15160), ('不能', 15010), ('好找', 14862), ('态度', 14851), ('沙拉', 14738), ('真是', 14738), ('性价比', 14524), ('实在', 14195), ('直接', 14065), ('划算', 13999), ('蔬菜', 13907), ('分量', 13825), ('真心', 13742), ('时间', 13709), ('希望', 13643), ('水果', 13387), ('不要', 13305), ('之后', 13210), ('招牌', 13022), ('后来', 13014), ('门口', 12968), ('菜单', 12966), ('外面', 12952), ('好像', 12882), ('排队', 12656), ('好多', 12653), ('进去', 12550)]\n"
     ]
    }
   ],
   "source": [
    "print(counts.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83b042f1-93a3-434e-ab50-cb4e52ab42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sep_content'] = df_train['sep_content'].apply(lambda x:excludestops(x, expand_stop_words))\n",
    "df_valid['sep_content'] = df_valid['sep_content'].apply(lambda x:excludestops(x, expand_stop_words))\n",
    "df_testa['sep_content'] = df_testa['sep_content'].apply(lambda x:excludestops(x, expand_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e18dd99d-c2fd-4d86-bcff-812fc18d88fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>sep_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>1</td>\n",
       "      <td>萌死 棒棒糖 可爱 好奇 棒棒糖 东西 土老冒 见识 机会 介绍 棒棒糖 德国 不会 很甜 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>参加 活动 这家 整体 感觉 环境 只能 中等 提供 菜品 不是 很多 当然 商家 避免 参...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...</td>\n",
       "      <td>0</td>\n",
       "      <td>同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 奶...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2  人同行 点个小吃 榴莲酥 榴莲味道不足 松软 奶味浓 虾饺 好吃 两颗大虾仁 皮蛋粥 皮蛋多...   \n",
       "\n",
       "   service_waiters_attitude                                        sep_content  \n",
       "0                         1  萌死 棒棒糖 可爱 好奇 棒棒糖 东西 土老冒 见识 机会 介绍 棒棒糖 德国 不会 很甜 ...  \n",
       "1                        -2  参加 活动 这家 整体 感觉 环境 只能 中等 提供 菜品 不是 很多 当然 商家 避免 参...  \n",
       "2                         0  同行 点个 小吃 榴莲 榴莲 味道 不足 松软 奶味 虾饺 好吃 两颗 虾仁 皮蛋 皮蛋 奶...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e930d15-6c97-4635-8475-3a7e0ecbd34d",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab81ce6d-ff04-4319-bc46-7ba4b60892ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:829\n",
      "min:2\n",
      "mean:84.99480740740741\n",
      "Overlength: 25129 / 135000\n",
      "135000\n"
     ]
    }
   ],
   "source": [
    "sentences_train = list(df_train['sep_content'])\n",
    "sentences_valid = list(df_valid['sep_content'])\n",
    "sentences_testa = list(df_testa['sep_content'])\n",
    "sentences = sentences_train + sentences_valid + sentences_testa\n",
    "word_list = \" \".join(sentences).split()\n",
    "lenlist = [len(sentence.split()) for sentence in sentences]\n",
    "print('max:{}\\nmin:{}\\nmean:{}'.format(np.max(lenlist), np.min(lenlist), np.mean(lenlist)))\n",
    "\n",
    "cnt = collections.Counter(lenlist)\n",
    "sum_sentences, sum_overlength = 0, 0\n",
    "for key in cnt:\n",
    "    if key > config['padding_length']:\n",
    "        sum_overlength += cnt[key]\n",
    "    sum_sentences += cnt[key]\n",
    "print('Overlength: {} / {}'.format(sum_overlength, sum_sentences))\n",
    "print(sum_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "341cfd2a-b1a6-4306-a828-667b3fa3d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sentence):\n",
    "    PAD = ' <PAD>'\n",
    "    pad_size = config['padding_length']\n",
    "    senlist = sentence.split()\n",
    "    sentence_len = len(senlist)\n",
    "    if sentence_len < pad_size:\n",
    "        sentence += PAD * (pad_size - sentence_len)\n",
    "    else:\n",
    "        sentence = \" \".join(senlist[-pad_size:])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6055b02d-f3bd-4697-a895-3a8c64269978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sep_content'] = df_train['sep_content'].apply(lambda x:padding(x))\n",
    "df_valid['sep_content'] = df_valid['sep_content'].apply(lambda x:padding(x))\n",
    "df_testa['sep_content'] = df_testa['sep_content'].apply(lambda x:padding(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd345b2",
   "metadata": {},
   "source": [
    "## Building Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95fdd4c1-1584-4a19-af3c-04cc62911745",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = list(df_train['sep_content'])\n",
    "sentences_valid = list(df_valid['sep_content'])\n",
    "sentences_testa = list(df_testa['sep_content'])\n",
    "sentences = sentences_train + sentences_valid + sentences_testa\n",
    "word_list = \" \".join(sentences).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e781f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(word_list))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84beee1e-ac0c-44ab-9ce3-b853858ccc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90822"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23db1f0-ce92-46f0-b7d2-f26030b53be1",
   "metadata": {},
   "source": [
    "## Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfbd7a8d-2f56-4655-bd34-f6a2f37e1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(seed):\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "same_seed(config['seed'])\n",
    "\n",
    "#def seed_worker(worker_id):\n",
    "#    worker_seed = torch.initial_seed() % 2**32\n",
    "#    numpy.random.seed(worker_seed)\n",
    "#    random.seed(worker_seed)\n",
    "\n",
    "#g = torch.Generator()\n",
    "#g.manual_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6317a-4b5d-4851-98e7-675a1aacbe9d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c00a1f89-672a-4d27-ac40-353dced26b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = list(df_train['service_waiters_attitude'])\n",
    "labels_train = [i + 2 for i in labels_train]\n",
    "labels_valid = list(df_valid['service_waiters_attitude'])\n",
    "labels_valid = [i + 2 for i in labels_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b107ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences, labels):\n",
    "    inputs = []\n",
    "    for sen in sentences:\n",
    "        inputs.append([word2idx[n] for n in sen.split()])\n",
    "\n",
    "    targets = []\n",
    "    for out in labels:\n",
    "        targets.append(out) # To using Torch Softmax Loss function\n",
    "    return torch.LongTensor(inputs), torch.LongTensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fefe820-e41c-442c-9993-81a445e8b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, target_train = make_data(sentences_train, labels_train)\n",
    "input_valid, target_valid = make_data(sentences_valid, labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afb505d1-86a9-43cd-85d0-e87c75503f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(torch.tensor(input_train), torch.tensor(target_train))\n",
    "valid_dataset = Data.TensorDataset(torch.tensor(input_valid), torch.tensor(target_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c14ec059-0d69-439c-967c-5e5ca5765145",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True,\n",
    "#    worker_init_fn=seed_worker,\n",
    "#    generator=g,\n",
    ")\n",
    "valid_loader = Data.DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True,\n",
    "#    worker_init_fn=seed_worker,\n",
    "#    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0b76f-cd00-4420-b504-c862678efc54",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cd0c839-2010-44b9-bcf0-3872ee4a2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SALSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SALSTM, self).__init__()\n",
    "        self.n_layers = 2\n",
    "        self.hidden_dim = 512\n",
    "        self.embedding_dim = 512\n",
    "        self.dropout = 0.5\n",
    "        self.n_vocab = vocab_size\n",
    "        self.num_classes = config['num_classes']\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_vocab, self.embedding_dim, padding_idx = word2idx['<PAD>'])\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.embedding_dim,\n",
    "            self.hidden_dim,\n",
    "            self.n_layers,\n",
    "            dropout = self.dropout, \n",
    "            batch_first = True,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features = self.hidden_dim,\n",
    "            out_features = self.num_classes\n",
    "        ) \n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # x.size() = (batch_size, padding_size)\n",
    "        # h.size() = c.size() = (n_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        out = self.embedding(x) # out.size() = (batch_size, padding_size, embedding_dim)\n",
    "        out, hidden = self.lstm(out, hidden) # out.size() = (batch_size, padding_size, hidden_dim)\n",
    "        out = out[:, -1, :].squeeze(1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out) # out.size() = (batch_size, num_classes)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = (\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        )\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577296e-4143-4cce-8edd-7571844a59ba",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87ed6b58-d788-400c-932a-3cda2e109f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(labels, pred):\n",
    "    return f1_score(labels, pred, labels=[0, 1, 2, 3], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "301796a7-37f2-4f2c-912a-7ddb49d63b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    #criterion = AMSoftmax()\n",
    "    criterion = nn.CrossEntropyLoss()#.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "#\tscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#\t\toptimizer,\n",
    "#\t\teta_min=config['learning_rate']/50.0,\n",
    "#\t\tT_0=config['n_epochs']\n",
    "#\t)\n",
    "\n",
    "    if not os.path.isdir(config['save_path']):\n",
    "        os.mkdir(config['save_path'])\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    n_epochs = config['n_epochs']\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        acc_record, loss_record, record_count = 0.0, 0.0, 0\n",
    "        prediction = []\n",
    "        groundtruth = []\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "        train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        \n",
    "        for data, labels in train_pbar:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            hidden = model.init_hidden(config['batch_size'])\n",
    "            pred, hidden = model(data, hidden)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            pred_flate = pred.argmax(dim = 1)\n",
    "            acc = torch.mean((pred_flate == labels).float())\n",
    "            f1 = get_f1_score(labels.tolist(), pred_flate.tolist())\n",
    "            prediction += pred_flate.tolist()\n",
    "            groundtruth += labels.tolist()\n",
    "            \n",
    "            loss.backward()\n",
    "            gnorm = nn.utils.clip_grad_norm_(model.parameters(), config['clip_norm'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            record_count += 1\n",
    "            loss_record += loss.item()\n",
    "            acc_record += acc.item()\n",
    "            train_pbar.set_postfix({'loss': loss.item(), 'acc': acc.item(), 'f1': f1})\n",
    "            wandb.log({\"train/acc\": acc, \"train/loss\": loss, \"train/f1\": f1, \"train/grad_norm\": gnorm})\n",
    "            \n",
    "        train_acc = acc_record / record_count\n",
    "        train_loss = loss_record / record_count\n",
    "        train_f1 = get_f1_score(groundtruth, prediction)\n",
    "        \n",
    "        print('TRAIN: epoch:{}, loss:{:.3f}, acc:{:.3f}, f1_score:{:.3f}'.format(epoch + 1, train_loss, train_acc, train_f1))\n",
    "\n",
    "        # valid\n",
    "        model.eval()\n",
    "        \n",
    "        acc_record, loss_record, record_count = 0.0, 0.0, 0\n",
    "        prediction = []\n",
    "        groundtruth = []\n",
    "        valid_pbar = tqdm(valid_loader, position=0, leave=True)\n",
    "        valid_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        for data, labels in valid_pbar:\n",
    "\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                hidden = model.init_hidden(config['batch_size'])\n",
    "                pred, hidden = model(data, hidden)\n",
    "                loss = criterion(pred, labels)\n",
    "                pred_flate = pred.argmax(dim=1)\n",
    "                acc = torch.mean((pred_flate == labels).float())\n",
    "                f1 = get_f1_score(labels.tolist(), pred_flate.tolist())\n",
    "                prediction += pred_flate.tolist()\n",
    "                groundtruth += labels.tolist()\n",
    "\n",
    "            record_count += 1\n",
    "            loss_record += loss.item()\n",
    "            acc_record += acc.item()\n",
    "            valid_pbar.set_postfix({'loss': loss.item(), 'acc': acc.item(), 'f1': f1})\n",
    "        \n",
    "        valid_acc = acc_record / record_count\n",
    "        valid_loss = loss_record / record_count\n",
    "        valid_f1 = get_f1_score(groundtruth, prediction)\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "        print('VALID: epoch:{}, loss:{:.3f}, acc:{:.3f}, f1_score:{:.3f}'.format(epoch + 1, valid_loss, valid_acc, valid_f1))\n",
    "        \n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            torch.save(model.state_dict(), config['save_path'] + 'model.ckpt')\n",
    "            print('Saving model with f1 {:.5f}'.format(best_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7199e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7756976bad1d4adaad7f72fdb51861cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:1, loss:0.818, acc:0.679, f1_score:0.486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb23ff6e3394b218ab28b1771ced090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:1, loss:0.594, acc:0.779, f1_score:0.650\n",
      "Saving model with f1 0.64972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e7ec946682433eaf4e4d0b9020edd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:2, loss:0.551, acc:0.798, f1_score:0.687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e282242270453f9713ea7339d69414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:2, loss:0.542, acc:0.792, f1_score:0.678\n",
      "Saving model with f1 0.67777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e631f29f8be4a97809fac3103fc1e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:3, loss:0.451, acc:0.837, f1_score:0.752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb1b2d16b3f4ef39b7dcab2edb3b9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:3, loss:0.573, acc:0.792, f1_score:0.690\n",
      "Saving model with f1 0.69022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5364da33843418daafd761195609173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:4, loss:0.349, acc:0.879, f1_score:0.815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bd4019b26a406c988e0962e3b453bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:4, loss:0.631, acc:0.786, f1_score:0.689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb1a64a5cda417d853f884967356c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:5, loss:0.247, acc:0.919, f1_score:0.874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648beee3088e4fd1b4ad6cb2351bab78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:5, loss:0.721, acc:0.784, f1_score:0.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e92540ff144514b81952b619a3f6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:6, loss:0.181, acc:0.945, f1_score:0.913\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4045fde86b04475c970971698426e01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:6, loss:0.768, acc:0.780, f1_score:0.681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb7cf8625c64ab7b6260ed8179928a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:7, loss:0.135, acc:0.961, f1_score:0.938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d14b56e5b9441df91d723e8d645de83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:7, loss:0.973, acc:0.770, f1_score:0.673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61a20a1c94b47309b79d374071802cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:8, loss:0.105, acc:0.972, f1_score:0.956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc92788226d454e9d7956d1deb03f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:8, loss:1.029, acc:0.772, f1_score:0.676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef65d4caa9340cb8ef6656db426f54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:9, loss:0.084, acc:0.978, f1_score:0.965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8715595b16df4242a88a216ffad288a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:9, loss:1.082, acc:0.773, f1_score:0.665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52144cb0ca8848d9be1160f6d11c4c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:10, loss:0.068, acc:0.982, f1_score:0.973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a3d4c9a9046dfa85e71cc1e238e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:10, loss:1.154, acc:0.774, f1_score:0.675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>▁▅▇▄▆▆▆▅▇▆▇▆▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>train/f1</td><td>▁▃▅▃▅▅▅▅▆▄▅▆▇▆▆▅▇▇▇▅▇█▇█▇███████████████</td></tr><tr><td>train/grad_norm</td><td>▂▅▂▄▂▂▂▄▃▄▂▄▂▄▃▃█▄▂▅▄▃▄▃▃▅▁▄▂▂▆▃▄▇▆▂▁▃▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▅▄▄▃▅▃▃▃▄▂▃▂▃▂▂▂▂▂▁▂▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>0.95312</td></tr><tr><td>train/f1</td><td>0.91012</td></tr><tr><td>train/grad_norm</td><td>2.01077</td></tr><tr><td>train/loss</td><td>0.21086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM</strong> at: <a href='https://wandb.ai/acsdf/SA/runs/v4qra3db' target=\"_blank\">https://wandb.ai/acsdf/SA/runs/v4qra3db</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240227_175001-v4qra3db\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SALSTM().to(device)\n",
    "trainer(train_loader, valid_loader, model, config, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519392a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
