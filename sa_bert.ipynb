{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374a5f79-30ca-4b7c-9d89-1c04d22258d2",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0eceb29-d217-4886-bf41-47a25d77182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Mubuky\\.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06c156",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import warnings\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aee5b72-12ce-433e-ae30-b0fe6de13a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea89b9a-3b2b-4a99-b386-4581e327f98d",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8d10ef-7eae-4121-9f71-5737941aa100",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "\t'seed': 5201314,\n",
    "\t'batch_size': 16,\n",
    "\t'learning_rate': 1e-5,\n",
    "\t'num_workers': 0,\n",
    "\t'save_path': './models/',\n",
    "#\t'output_path': './pred.csv',\n",
    "\t'n_epochs': 3,\n",
    "    'padding_length': 512,\n",
    "    'num_classes': 4  # -2, -1, 0, 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce649823-963e-4c75-afb8-8ead00e8fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: mubuky (acsdf). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Jupyter Notebook\\ema-lab\\finalproject\\wandb\\run-20240422_174933-ap6is0pa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/acsdf/SA/runs/ap6is0pa' target=\"_blank\">BERT</a></strong> to <a href='https://wandb.ai/acsdf/SA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/acsdf/SA' target=\"_blank\">https://wandb.ai/acsdf/SA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/acsdf/SA/runs/ap6is0pa' target=\"_blank\">https://wandb.ai/acsdf/SA/runs/ap6is0pa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/acsdf/SA/runs/ap6is0pa?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x18989ae5130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = \"SA\",\n",
    "    name = \"BERT\",\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff5478-1582-4f12-a070-ccd6fbaee273",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230cac44-d1fb-4a41-a0a6-8b7d86c21172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "df_train = pd.read_csv(data_path + 'train.csv')\n",
    "df_valid = pd.read_csv(data_path + 'valid.csv')\n",
    "df_testa = pd.read_csv(data_path + 'testa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc4492c-8cf3-44b1-b3a3-aea7ecf3e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[ : , ['content', 'service_waiters_attitude']]\n",
    "df_valid = df_valid.loc[ : , ['content', 'service_waiters_attitude']]\n",
    "df_testa = df_testa.loc[ : , ['content', 'service_waiters_attitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb5309-8745-4e63-a319-d8e5dd36d945",
   "metadata": {},
   "source": [
    "## Pretreatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7989a-d9dd-48e6-b8c5-cb8ebf3b631a",
   "metadata": {},
   "source": [
    "### 繁体转简体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c1d3f4-c5d3-41d3-8de4-1a3afdd2928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencc import OpenCC\n",
    "\n",
    "cc = OpenCC('t2s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de70b66-c392-4143-8893-4659bc4bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(lambda x:cc.convert(x))\n",
    "df_valid['content'] = df_valid['content'].apply(lambda x:cc.convert(x))\n",
    "df_testa['content'] = df_testa['content'].apply(lambda x:cc.convert(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0e8c0-31ae-44d4-9a80-8cac4aaee06c",
   "metadata": {},
   "source": [
    "### 正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c154afa4-0d6b-418b-8a21-8e82646b5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_sentence(content):\n",
    "    decimal_regex = re.compile(r\"[^a-zA-Z]\\d+\")\n",
    "\n",
    "    content = content.replace(\"\\r\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    content = decimal_regex.sub(r\"\", content)\n",
    "\n",
    "    #return \"\".join(re.findall('[\\u4e00-\\u9fa5]+', content, re.S))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833ea410-effd-4527-bbd2-78f3f3c766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(lambda x:regular_sentence(x))\n",
    "df_valid['content'] = df_valid['content'].apply(lambda x:regular_sentence(x))\n",
    "df_testa['content'] = df_testa['content'].apply(lambda x:regular_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23db1f0-ce92-46f0-b7d2-f26030b53be1",
   "metadata": {},
   "source": [
    "## Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfbd7a8d-2f56-4655-bd34-f6a2f37e1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(seed):\n",
    "#    torch.use_deterministic_algorithms(True)\n",
    "#    torch.backends.cudnn.enabled = False\n",
    "#    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "#    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "same_seed(config['seed'])\n",
    "\n",
    "#def seed_worker(worker_id):\n",
    "#    worker_seed = torch.initial_seed() % 2**32\n",
    "#    numpy.random.seed(worker_seed)\n",
    "#    random.seed(worker_seed)\n",
    "\n",
    "#g = torch.Generator()\n",
    "#g.manual_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6317a-4b5d-4851-98e7-675a1aacbe9d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00a1f89-672a-4d27-ac40-353dced26b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = list(df_train['content'])\n",
    "sentences_valid = list(df_valid['content'])\n",
    "sentences_testa = list(df_testa['content'])\n",
    "labels_train = list(df_train['service_waiters_attitude'])\n",
    "labels_train = [i + 2 for i in labels_train]\n",
    "labels_valid = list(df_valid['service_waiters_attitude'])\n",
    "labels_valid = [i + 2 for i in labels_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56609170-7172-48c3-b741-66717889e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SADataset(Data.Dataset):\n",
    "    def __init__(self, data, labels = None):\n",
    "        self.data = data\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return data, label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24de7138-7960-4900-9326-1911a83a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SADataset(sentences_train, labels_train)\n",
    "valid_dataset = SADataset(sentences_valid, labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14ec059-0d69-439c-967c-5e5ca5765145",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True,\n",
    "#    worker_init_fn=seed_worker,\n",
    "#    generator=g,\n",
    ")\n",
    "valid_loader = Data.DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True,\n",
    "#    worker_init_fn=seed_worker,\n",
    "#    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577296e-4143-4cce-8edd-7571844a59ba",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ed6b58-d788-400c-932a-3cda2e109f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(labels, pred):\n",
    "    return f1_score(labels, pred, labels=[0, 1, 2, 3], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "301796a7-37f2-4f2c-912a-7ddb49d63b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, tokenizer, model, config, device):\n",
    "    #criterion = AMSoftmax()\n",
    "    criterion = nn.CrossEntropyLoss()#.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "#\tscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#\t\toptimizer,\n",
    "#\t\teta_min=config['learning_rate']/50.0,\n",
    "#\t\tT_0=config['n_epochs']\n",
    "#\t)\n",
    "\n",
    "    if not os.path.isdir(config['save_path']):\n",
    "        os.mkdir(config['save_path'])\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    n_epochs = config['n_epochs']\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        acc_record, loss_record, record_count = 0.0, 0.0, 0\n",
    "        prediction = []\n",
    "        groundtruth = []\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "        train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        \n",
    "        for data, labels in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data = tokenizer(data, max_length = 108, padding = True, truncation = True, return_tensors = 'pt')\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(**data, labels = labels)\n",
    "            pred = pred[1]\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            pred_flate = pred.argmax(dim = 1)\n",
    "            acc = torch.mean((pred_flate == labels).float())\n",
    "            f1 = get_f1_score(labels.tolist(), pred_flate.tolist())\n",
    "            prediction += pred_flate.tolist()\n",
    "            groundtruth += labels.tolist()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            record_count += 1\n",
    "            loss_record += loss.item()\n",
    "            acc_record += acc.item()\n",
    "            train_pbar.set_postfix({'loss': loss.item(), 'acc': acc.item(), 'f1': f1})\n",
    "            wandb.log({\"train/acc\": acc, \"train/loss\": loss, \"train/f1\": f1})\n",
    "            \n",
    "        train_acc = acc_record / record_count\n",
    "        train_loss = loss_record / record_count\n",
    "        train_f1 = get_f1_score(groundtruth, prediction)\n",
    "        \n",
    "        print('TRAIN: epoch:{}, loss:{:.3f}, acc:{:.3f}, f1_score:{:.3f}'.format(epoch + 1, train_loss, train_acc, train_f1))\n",
    "\n",
    "        # valid\n",
    "        model.eval()\n",
    "        \n",
    "        acc_record, loss_record, record_count = 0.0, 0.0, 0\n",
    "        prediction = []\n",
    "        groundtruth = []\n",
    "        valid_pbar = tqdm(valid_loader, position=0, leave=True)\n",
    "        valid_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        for data, labels in valid_pbar:\n",
    "\n",
    "            data = tokenizer(data, max_length = config['padding_length'], padding = True, truncation = True, return_tensors = 'pt')\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = model(**data, labels = labels)\n",
    "                pred = pred[1]\n",
    "                \n",
    "                loss = criterion(pred, labels)\n",
    "                pred_flate = pred.argmax(dim=1)\n",
    "                acc = torch.mean((pred_flate == labels).float())\n",
    "                f1 = get_f1_score(labels.tolist(), pred_flate.tolist())\n",
    "                prediction += pred_flate.tolist()\n",
    "                groundtruth += labels.tolist()\n",
    "\n",
    "            record_count += 1\n",
    "            loss_record += loss.item()\n",
    "            acc_record += acc.item()\n",
    "            valid_pbar.set_postfix({'loss': loss.item(), 'acc': acc.item(), 'f1': f1})\n",
    "        \n",
    "        valid_acc = acc_record / record_count\n",
    "        valid_loss = loss_record / record_count\n",
    "        valid_f1 = get_f1_score(groundtruth, prediction)\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "        print('VALID: epoch:{}, loss:{:.3f}, acc:{:.3f}, f1_score:{:.3f}'.format(epoch + 1, valid_loss, valid_acc, valid_f1))\n",
    "        \n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            torch.save(model.state_dict(), config['save_path'] + 'model.ckpt')\n",
    "            print('Saving model with f1 {:.5f}'.format(best_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a53d34b-fc43-419c-90d5-c02ee1a4acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76fae37d-a483-463c-a21c-0578146a98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertconfig = BertConfig.from_pretrained('google-bert/bert-base-chinese', num_labels = config['num_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b58c9b-3fcc-4f55-b384-e1f5f69e21e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-chinese', config = bertconfig).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7199e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1034b8ade44298bb6047a4afe30787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:1, loss:0.941, acc:0.607, f1_score:0.493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8e53a27e914841988d0c29db0da58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:1, loss:0.584, acc:0.813, f1_score:0.733\n",
      "Saving model with f1 0.73267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe796d2436461cb318c48b2d969e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:2, loss:0.880, acc:0.635, f1_score:0.538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144d731571d74918be75d3f311c23528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:2, loss:0.519, acc:0.834, f1_score:0.756\n",
      "Saving model with f1 0.75631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9b390d7dba4353967a2c81611c50dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:3, loss:0.825, acc:0.660, f1_score:0.578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec1c13f1a2c4de49e9088bfc7009a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:3, loss:0.554, acc:0.810, f1_score:0.736\n"
     ]
    }
   ],
   "source": [
    "trainer(train_loader, valid_loader, tokenizer, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13510a99-07f9-4f80-b0c3-b5089a71ec13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>▃▁▅▅▅▃▃▄▁▃▄▅▂▆▄▄▁█▃▂▅▂▅▄▆▅▄▇▃▄▅▄▃▂▄▅▁▄▄▂</td></tr><tr><td>train/f1</td><td>▃▂▃▁▅▂▂▃▂▂▃▅▁▂▅▂▂█▂▂▃▁▃▄▃▄▂█▂▂▆▄▂▄▄▂▂▃▁▁</td></tr><tr><td>train/loss</td><td>▆█▅▄▄▇█▃▆▇▅▆▆▃▄▃▆▂▆▆▅▆▄▄▃▆▄▁▅▅▅▄▆▇▅▆█▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>0.6875</td></tr><tr><td>train/f1</td><td>0.48397</td></tr><tr><td>train/loss</td><td>0.79499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BERT</strong> at: <a href='https://wandb.ai/acsdf/SA/runs/ap6is0pa' target=\"_blank\">https://wandb.ai/acsdf/SA/runs/ap6is0pa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240422_174933-ap6is0pa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519392a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
